| **Nom de l'article**                                                                                   | **Modèle utilisé**                                                                                   | **Corpus de données**                                                                                                           | **Méthode**                                                                                                                     | **Question de recherche**                                                                                                     |
|-------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------|
| The VoiceMOS Challenge 2023: Zero-Shot Subjective Speech Quality Prediction for Multiple Domains      | Divers modèles soumis par les participants : CNN, Transformer, Wav2Vec 2.0, XLSR, HuBERT, etc.        | VCC2022 (Voice Conversion Challenge 2022), BVCC (Blind Voice Conversion Challenge), NISQA (NISQA speech corpus), TCD-VoIP, LIVE Speech Quality Database | Les participants ont exploré des architectures variées, telles que les modèles pré-entraînés et les approches "zero-shot", pour prédire les Mean Opinion Scores (MOS) sur des corpus de test inconnus. Un cadre d'évaluation standardisé a été utilisé pour la comparaison | Comment améliorer les performances des modèles de prédiction MOS "zero-shot" pour la qualité vocale sur divers corpus de test non vus pendant l'entraînement ? |
| LE-SSL-MOS: Self-Supervised Learning MOS Prediction with Listener Enhancement                          | Modèle LE-SSL (Listener-Enhanced Self-Supervised Learning) basé sur Wav2Vec 2.0 et un module d'amélioration d'auditeur | Corpus VC (Voice Conversion), VCC2022, et des données internes annotées pour la qualité vocale                                    | Utilise Wav2Vec 2.0 avec une phase d'apprentissage auto-supervisé, suivie d'une intégration des caractéristiques de l'auditeur pour affiner la prédiction MOS | Comment les caractéristiques spécifiques de l'auditeur (comme la sensibilité ou les préférences auditives) peuvent-elles être incorporées pour améliorer la prédiction de la qualité vocale auto-supervisée ? |
| SQAT-LD: SPeech Quality Assessment Transformer Utilizing Listener Dependent Modeling for Zero-Shot Out-of-Domain MOS Prediction | Transformer avec modélisation dépendante de l'auditeur (incorpore des informations spécifiques à chaque auditeur) | VCC2022, BVCC, et des corpus internes d'évaluation MOS                                                        | Modélisation de la dépendance à l'auditeur via un Transformer pour capturer les variations subjectives de l'évaluation de la qualité vocale en mode "zero-shot". Utilisation de l'attention pour pondérer l'impact des auditeurs | Comment la modélisation basée sur les auditeurs peut-elle être exploitée pour améliorer la prédiction de la qualité vocale en mode "zero-shot", particulièrement sur des données hors du domaine d'entraînement ? |
